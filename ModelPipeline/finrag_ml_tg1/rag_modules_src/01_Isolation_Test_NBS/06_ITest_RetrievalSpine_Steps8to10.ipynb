{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653df20d",
   "metadata": {},
   "source": [
    "## Isolation Tests and Skeletons\n",
    "- Grain Validation, Assembler Tests.\n",
    "- STEP 1 to 9 finale except LLM ( assembling check. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b93cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c6d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded Stage 2 Meta: 469,252 rows\n",
      "\n",
      "✓ Extracted sentence_pos from sentenceID\n",
      "  Valid positions: 469,252\n",
      "  Failed extractions: 0\n",
      "\n",
      "================================================================================\n",
      "VALIDATION 1: Grain Uniqueness Check\n",
      "================================================================================\n",
      "\n",
      "Total unique grain combinations: 469,252\n",
      "Duplicate grains (row_count > 1): 0\n",
      "\n",
      "✓ GRAIN IS UNIQUE - No duplicates found\n",
      "  (cik_int, report_year, docID, section_name, sentence_pos) → Unique sentence\n",
      "\n",
      "================================================================================\n",
      "VALIDATION 2: sentenceID ↔ Grain Bijection\n",
      "================================================================================\n",
      "\n",
      "Total unique sentenceIDs: 469,252\n",
      "sentenceIDs with multiple grains: 0\n",
      "\n",
      "✓ BIJECTION CONFIRMED - Each sentenceID maps to exactly one grain\n",
      "\n",
      "================================================================================\n",
      "VALIDATION 3: Sort Order Test (Sample Data)\n",
      "================================================================================\n",
      "\n",
      "Sample sentences sorted by (company, year ASC, section, doc, pos):\n",
      "\n",
      "shape: (20, 7)\n",
      "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ name         ┆ report_year ┆ section_nam ┆ docID       ┆ sentence_po ┆ sentenceID  ┆ text_previe │\n",
      "│ ---          ┆ ---         ┆ e           ┆ ---         ┆ s           ┆ ---         ┆ w           │\n",
      "│ str          ┆ i64         ┆ ---         ┆ str         ┆ ---         ┆ str         ┆ ---         │\n",
      "│              ┆             ┆ str         ┆             ┆ i16         ┆             ┆ str         │\n",
      "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ MICROSOFT    ┆ 2018        ┆ ITEM_1A     ┆ 0000789019_ ┆ 0           ┆ 0000789019_ ┆ Item 1A     │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2018   ┆             ┆ 10-K_2018_s ┆ ITEM 1A.    │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆             │\n",
      "│ MICROSOFT    ┆ 2018        ┆ ITEM_1A     ┆ 0000789019_ ┆ 1           ┆ 0000789019_ ┆ RISK        │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2018   ┆             ┆ 10-K_2018_s ┆ FACTORS Our │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ operations  │\n",
      "│              ┆             ┆             ┆             ┆             ┆             ┆ an…         │\n",
      "│ MICROSOFT    ┆ 2018        ┆ ITEM_1A     ┆ 0000789019_ ┆ 2           ┆ 0000789019_ ┆ We face     │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2018   ┆             ┆ 10-K_2018_s ┆ intense     │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ competition │\n",
      "│              ┆             ┆             ┆             ┆             ┆             ┆ ac…         │\n",
      "│ MICROSOFT    ┆ 2018        ┆ ITEM_1A     ┆ 0000789019_ ┆ 3           ┆ 0000789019_ ┆ Competition │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2018   ┆             ┆ 10-K_2018_s ┆ in the      │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ technology  │\n",
      "│              ┆             ┆             ┆             ┆             ┆             ┆ …           │\n",
      "│ MICROSOFT    ┆ 2018        ┆ ITEM_1A     ┆ 0000789019_ ┆ 4           ┆ 0000789019_ ┆ Barriers to │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2018   ┆             ┆ 10-K_2018_s ┆ entry in    │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ many of o…  │\n",
      "│ …            ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           ┆ …           │\n",
      "│ MICROSOFT    ┆ 2019        ┆ ITEM_1A     ┆ 0000789019_ ┆ 3           ┆ 0000789019_ ┆ Competition │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2019   ┆             ┆ 10-K_2019_s ┆ in the      │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ technology  │\n",
      "│              ┆             ┆             ┆             ┆             ┆             ┆ …           │\n",
      "│ MICROSOFT    ┆ 2019        ┆ ITEM_1A     ┆ 0000789019_ ┆ 4           ┆ 0000789019_ ┆ Barriers to │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2019   ┆             ┆ 10-K_2019_s ┆ entry in    │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ many of o…  │\n",
      "│ MICROSOFT    ┆ 2019        ┆ ITEM_1A     ┆ 0000789019_ ┆ 5           ┆ 0000789019_ ┆ Our ability │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2019   ┆             ┆ 10-K_2019_s ┆ to remain   │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_1…   ┆ competit…   │\n",
      "│ MICROSOFT    ┆ 2019        ┆ ITEM_7      ┆ 0000789019_ ┆ 0           ┆ 0000789019_ ┆ Item 7 ITEM │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2019   ┆             ┆ 10-K_2019_s ┆ 7.          │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_7…   ┆             │\n",
      "│ MICROSOFT    ┆ 2019        ┆ ITEM_7      ┆ 0000789019_ ┆ 1           ┆ 0000789019_ ┆ MANAGEMENT’ │\n",
      "│ CORP         ┆             ┆             ┆ 10-K_2019   ┆             ┆ 10-K_2019_s ┆ S           │\n",
      "│              ┆             ┆             ┆             ┆             ┆ ection_7…   ┆ DISCUSSION  │\n",
      "│              ┆             ┆             ┆             ┆             ┆             ┆ AND AN…     │\n",
      "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n",
      "\n",
      "================================================================================\n",
      "VALIDATION 4: Simulated Assembly Format\n",
      "================================================================================\n",
      "\n",
      "Assembled context preview (first 1000 chars):\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "=== MICROSOFT CORP | 2018 | ITEM_1A ===\n",
      "\n",
      "Item 1A ITEM 1A.\n",
      "\n",
      "RISK FACTORS Our operations and financial results are subject to various risks and uncertainties, including those described below, that could adversely affect our business, financial condition, results of operations, cash flows, and the trading price of our common stock.\n",
      "\n",
      "We face intense competition across all markets for our products and services, which may lead to lower revenue or operating margins.\n",
      "\n",
      "Competition in the technology sector Our competitors range in size from diversified global companies with significant research and development resources to small, specialized firms whose narrower product lines may let them be more effective in deploying technical, marketing, and financial resources.\n",
      "\n",
      "Barriers to entry in many of our businesses are low and many of the areas in which we compete evolve rapidly with changing and disruptive technologies, shifting user needs, and frequent introductions of new products and services.\n",
      "\n",
      "Ou\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Total assembled length: 8,075 characters\n",
      "\n",
      "================================================================================\n",
      "GRAIN VALIDATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ GRAIN VALIDATED:\n",
      "  • (cik_int, report_year, docID, section_name, sentence_pos) is UNIQUE\n",
      "  • Functionally equivalent to sentenceID\n",
      "  • Sort order produces logical chronological grouping\n",
      "  • Ready to implement ContextAssembler\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grain Validation: Verify (company, year, doc, section, pos) = Unique Sentence\n",
    "\n",
    "Tests that our sort key is functionally equivalent to sentenceID.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import polars as pl\n",
    "\n",
    "# Setup\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# Load Stage 2 Meta + Extract sentence_pos\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.sentence_utils import extract_sentence_position\n",
    "\n",
    "meta_path = model_root / \"finrag_ml_tg1/data_cache/meta_embeds/finrag_fact_sentences_meta_embeds.parquet\"\n",
    "meta_df = pl.read_parquet(meta_path)\n",
    "\n",
    "print(f\"✓ Loaded Stage 2 Meta: {len(meta_df):,} rows\\n\")\n",
    "\n",
    "# Extract sentence_pos\n",
    "meta_df = extract_sentence_position(meta_df, 'sentenceID')\n",
    "\n",
    "print(f\"✓ Extracted sentence_pos from sentenceID\")\n",
    "print(f\"  Valid positions: {meta_df.filter(pl.col('sentence_pos') != -1).height:,}\")\n",
    "print(f\"  Failed extractions: {meta_df.filter(pl.col('sentence_pos') == -1).height:,}\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# VALIDATION 1: Check Uniqueness of (cik, year, doc, section, pos)\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDATION 1: Grain Uniqueness Check\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Group by the functional key\n",
    "grain_check = meta_df.group_by([\n",
    "    'cik_int',\n",
    "    'report_year', \n",
    "    'docID',\n",
    "    'section_name',\n",
    "    'sentence_pos'\n",
    "]).agg([\n",
    "    pl.len().alias('row_count'),\n",
    "    pl.col('sentenceID').n_unique().alias('unique_sentence_ids')\n",
    "])\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = grain_check.filter(pl.col('row_count') > 1)\n",
    "\n",
    "print(f\"Total unique grain combinations: {len(grain_check):,}\")\n",
    "print(f\"Duplicate grains (row_count > 1): {len(duplicates)}\")\n",
    "print()\n",
    "\n",
    "if len(duplicates) == 0:\n",
    "    print(\"✓ GRAIN IS UNIQUE - No duplicates found\")\n",
    "    print(\"  (cik_int, report_year, docID, section_name, sentence_pos) → Unique sentence\")\n",
    "else:\n",
    "    print(\"✗ GRAIN HAS DUPLICATES - Multiple sentences map to same key:\")\n",
    "    print(duplicates.sort('row_count', descending=True).head(10))\n",
    "\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# VALIDATION 2: Check sentenceID vs Grain Equivalence\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDATION 2: sentenceID ↔ Grain Bijection\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# For each unique sentenceID, check if grain is also unique\n",
    "sentence_grain_map = meta_df.group_by('sentenceID').agg([\n",
    "    pl.len().alias('grain_count'),\n",
    "    pl.col('cik_int').n_unique().alias('unique_ciks'),\n",
    "    pl.col('docID').n_unique().alias('unique_docs'),\n",
    "    pl.col('sentence_pos').n_unique().alias('unique_positions')\n",
    "])\n",
    "\n",
    "# Check if any sentenceID maps to multiple grains\n",
    "multi_grain = sentence_grain_map.filter(\n",
    "    (pl.col('unique_ciks') > 1) | \n",
    "    (pl.col('unique_docs') > 1) | \n",
    "    (pl.col('unique_positions') > 1)\n",
    ")\n",
    "\n",
    "print(f\"Total unique sentenceIDs: {len(sentence_grain_map):,}\")\n",
    "print(f\"sentenceIDs with multiple grains: {len(multi_grain)}\")\n",
    "print()\n",
    "\n",
    "if len(multi_grain) == 0:\n",
    "    print(\"✓ BIJECTION CONFIRMED - Each sentenceID maps to exactly one grain\")\n",
    "else:\n",
    "    print(\"✗ BIJECTION BROKEN - Some sentenceIDs map to multiple grains:\")\n",
    "    print(multi_grain.head(10))\n",
    "\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# VALIDATION 3: Test Sort Order on Sample Data\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDATION 3: Sort Order Test (Sample Data)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Get a small sample: 2 companies, 2 years, 2 sections\n",
    "sample = meta_df.filter(\n",
    "    (pl.col('cik_int').is_in([1045810, 789019])) &  # NVIDIA, MSFT\n",
    "    (pl.col('report_year').is_in([2018, 2019])) &\n",
    "    (pl.col('section_name').is_in(['ITEM_1A', 'ITEM_7'])) &\n",
    "    (pl.col('sentence_pos') != -1) &\n",
    "    (pl.col('sentence_pos') <= 5)  # Just first 5 sentences per section\n",
    ")\n",
    "\n",
    "# Sort by our proposed order\n",
    "sorted_sample = sample.sort([\n",
    "    'name',           # company_name\n",
    "    'report_year',    # year ASC\n",
    "    'section_name',   # section\n",
    "    'docID',          # doc\n",
    "    'sentence_pos'    # position\n",
    "])\n",
    "\n",
    "# Display\n",
    "print(\"Sample sentences sorted by (company, year ASC, section, doc, pos):\\n\")\n",
    "print(sorted_sample.select([\n",
    "    'name',\n",
    "    'report_year',\n",
    "    'section_name',\n",
    "    'docID',\n",
    "    'sentence_pos',\n",
    "    'sentenceID',\n",
    "    pl.col('sentence').str.slice(0, 60).alias('text_preview')\n",
    "]).head(20))\n",
    "\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# VALIDATION 4: Simulated Assembly Output\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"VALIDATION 4: Simulated Assembly Format\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Simulate what ContextAssembler would produce\n",
    "context_parts = []\n",
    "current_group = None\n",
    "\n",
    "for row in sorted_sample.iter_rows(named=True):\n",
    "    group_key = (row['name'], row['report_year'], row['section_name'])\n",
    "    \n",
    "    # Insert header when group changes\n",
    "    if group_key != current_group:\n",
    "        if context_parts:\n",
    "            context_parts.append(\"\")  # Spacing between groups\n",
    "        \n",
    "        header = f\"=== {row['name']} | {row['report_year']} | {row['section_name']} ===\"\n",
    "        context_parts.append(header)\n",
    "        context_parts.append(\"\")\n",
    "        current_group = group_key\n",
    "    \n",
    "    # Add sentence\n",
    "    context_parts.append(row['sentence'])\n",
    "    context_parts.append(\"\")  # Double newline\n",
    "\n",
    "assembled_context = \"\\n\".join(context_parts)\n",
    "\n",
    "print(\"Assembled context preview (first 1000 chars):\")\n",
    "print(\"─\"*80)\n",
    "print(assembled_context[:1000])\n",
    "print(\"─\"*80)\n",
    "print()\n",
    "\n",
    "print(f\"Total assembled length: {len(assembled_context):,} characters\")\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# SUMMARY\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"GRAIN VALIDATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "all_valid = (\n",
    "    len(duplicates) == 0 and\n",
    "    len(multi_grain) == 0\n",
    ")\n",
    "\n",
    "if all_valid:\n",
    "    print(\"✓ GRAIN VALIDATED:\")\n",
    "    print(\"  • (cik_int, report_year, docID, section_name, sentence_pos) is UNIQUE\")\n",
    "    print(\"  • Functionally equivalent to sentenceID\")\n",
    "    print(\"  • Sort order produces logical chronological grouping\")\n",
    "    print(\"  • Ready to implement ContextAssembler\")\n",
    "else:\n",
    "    print(\"✗ GRAIN ISSUES DETECTED:\")\n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"  • {len(duplicates)} duplicate grain combinations\")\n",
    "    if len(multi_grain) > 0:\n",
    "        print(f\"  • {len(multi_grain)} sentenceIDs map to multiple grains\")\n",
    "    print(\"  • Investigate before implementing ContextAssembler\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e82c7",
   "metadata": {},
   "source": [
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "SUPPLY LINE 4: Complete RAG Retrieval Pipeline (Entity → Assembly)\n",
    "\n",
    "═══════════════════════════════════════════════════════════════════════════════\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d0691e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model root: d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\n",
      "\n",
      "Initializing pipeline components...\n",
      "\n",
      "[DEBUG] ✓ AWS credentials loaded from aws_credentials.env\n",
      "✓ FilterExtractor initialized with 21 companies\n",
      "  Using: finrag_dim_companies_21.parquet\n",
      "✓ All components initialized\n",
      "\n",
      "================================================================================\n",
      "QUERY\n",
      "================================================================================\n",
      "In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft discuss their AI strategy, competitive positioning, and supply chain risks between 2017 and 2020?\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXECUTING RETRIEVAL PIPELINE\n",
      "================================================================================\n",
      "\n",
      "→ Step 1: Entity Extraction\n",
      "  ✓ Companies: ['MSFT', 'NVDA']\n",
      "  ✓ Years: [2017, 2018, 2019, 2020]\n",
      "  ✓ Sections: ['ITEM_7', 'ITEM_1A']\n",
      "\n",
      "→ Step 2: Query Embedding\n",
      "  ✓ Generated 1024-d embedding\n",
      "\n",
      "→ Step 3: Metadata Filters\n",
      "  ✓ Filtered: {'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$in': [2017, 2018, 2019, 2020]}}, {'$or': [{'section_name': {'$eq': 'ITEM_7'}}, {'section_name': {'$eq': 'ITEM_1A'}}]}]}\n",
      "  ✓ Global: {'$and': [{'cik_int': {'$in': [789019, 1045810]}}, {'report_year': {'$gte': 2015}}]}\n",
      "\n",
      "→ Steps 4-5: S3 Vectors Retrieval (with variants)\n",
      "  ✓ Retrieved: 30 unique hits\n",
      "  ✓ Variants: 3\n",
      "\n",
      "→ Steps 6-7: Window Expansion + Deduplication\n",
      "  ✓ Expanded to: 188 unique sentences\n",
      "\n",
      "→ Step 10: Context Assembly\n",
      "  ✓ Assembled context ready\n",
      "\n",
      "================================================================================\n",
      "SAVING OUTPUT\n",
      "================================================================================\n",
      "\n",
      "✓ Saved assembled context to:\n",
      "  d:\\JoelDesktop folds_24\\NEU FALL2025\\MLops IE7374 Project\\FinSights\\ModelPipeline\\finrag_ml_tg1\\rag_modules_src\\test_outputs\\assembled_context_20251118_033721.txt\n",
      "\n",
      "File size: 42,022 bytes\n",
      "\n",
      "================================================================================\n",
      "CONTEXT PREVIEW (First 1000 chars)\n",
      "================================================================================\n",
      "\n",
      "=== MICROSOFT CORP | 2016 | ITEM_7 ===\n",
      "\n",
      "Many of these revenue and expenses are denominated in currencies other than the U.S. dollar.\n",
      "\n",
      "As a result, changes in foreign exchange rates may significantly affect revenue and expenses.\n",
      "\n",
      "The strengthening of the U.S. dollar relative to certain foreign currencies throughout fiscal year 2015, and continuing into fiscal year 2016, negatively impacted reported revenue and reduced reported expenses from our international operations.\n",
      "\n",
      "See a discussion of these factors and other risks under Risk Factors (Part I, Item 1A of this Form 10-K).\n",
      "\n",
      "Seasonality Our revenue historically has fluctuated quarterly and has generally been highest in the second quarter of our fiscal year due to corporate calendar year-end spending trends in our major markets and holiday season spending by consumers.\n",
      "\n",
      "Unearned Revenue Quarterly and annual revenue is impacted by the deferral of revenue, primarily including: • Revenue deferred on Windows 10 licenses to reflect ratable r\n",
      "\n",
      "[... truncated ...]\n",
      "\n",
      "================================================================================\n",
      "PIPELINE EXECUTION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "✓ Query processed successfully\n",
      "✓ Entities: 2 companies, 4 years\n",
      "✓ Embeddings: 1 base + 3 variants\n",
      "✓ S3 Retrieval: 30 hits\n",
      "✓ Expansion: 188 sentences\n",
      "✓ Assembly: 39,315 chars (~9,828 tokens)\n",
      "✓ Output saved: assembled_context_20251118_033721.txt\n",
      "\n",
      "================================================================================\n",
      "✓ SUPPLY LINE 4 COMPLETE - RAG PIPELINE WORKING END-TO-END\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "SUPPLY LINE 4: Complete RAG Retrieval Pipeline (Entity → Assembly)\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "Flow:\n",
    "    Query \n",
    "      → EntityAdapter \n",
    "      → QueryEmbedderV2 \n",
    "      → MetadataFilterBuilder\n",
    "      → VariantPipeline (internal to S3Retriever)\n",
    "      → S3VectorsRetriever\n",
    "      → SentenceExpander\n",
    "      → ContextAssembler\n",
    "      → Formatted LLM context\n",
    "\n",
    "Output: Saves assembled context as .txt file with metadata header\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup\n",
    "current = Path.cwd()\n",
    "for parent in [current] + list(current.parents):\n",
    "    if parent.name == \"ModelPipeline\":\n",
    "        model_root = parent\n",
    "        break\n",
    "if str(model_root) not in sys.path:\n",
    "    sys.path.insert(0, str(model_root))\n",
    "\n",
    "print(f\"✓ Model root: {model_root}\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# IMPORTS\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "from finrag_ml_tg1.loaders.ml_config_loader import MLConfig\n",
    "from finrag_ml_tg1.rag_modules_src.entity_adapter.entity_adapter import EntityAdapter\n",
    "from finrag_ml_tg1.rag_modules_src.utilities.query_embedder_v2 import (\n",
    "    EmbeddingRuntimeConfig,\n",
    "    QueryEmbedderV2\n",
    ")\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.metadata_filters import MetadataFilterBuilder\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.variant_pipeline import VariantPipeline\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.s3_retriever import S3VectorsRetriever\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.sentence_expander import SentenceExpander\n",
    "from finrag_ml_tg1.rag_modules_src.rag_pipeline.context_assembler import ContextAssembler\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# INITIALIZE COMPONENTS\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"Initializing pipeline components...\\n\")\n",
    "\n",
    "config = MLConfig()\n",
    "bedrock_client = config.get_bedrock_client()\n",
    "\n",
    "DIM_COMPANIES = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_companies_21.parquet\"\n",
    "DIM_SECTIONS = model_root / \"finrag_ml_tg1/data_cache/dimensions/finrag_dim_sec_sections.parquet\"\n",
    "\n",
    "# Step 1: Entity Adapter\n",
    "adapter = EntityAdapter(company_dim_path=DIM_COMPANIES, section_dim_path=DIM_SECTIONS)\n",
    "\n",
    "# Step 2: Query Embedder\n",
    "embedding_cfg = config.cfg[\"embedding\"]\n",
    "runtime_cfg = EmbeddingRuntimeConfig.from_ml_config(embedding_cfg)\n",
    "embedder = QueryEmbedderV2(runtime_cfg, boto_client=bedrock_client)\n",
    "\n",
    "# Step 3: Filter Builder\n",
    "filter_builder = MetadataFilterBuilder(config)\n",
    "\n",
    "# Step 4: Variant Pipeline\n",
    "variant_pipeline = VariantPipeline(config, adapter, embedder, bedrock_client)\n",
    "\n",
    "# Step 5: S3 Retriever\n",
    "retrieval_cfg = config.get_retrieval_config()\n",
    "retriever = S3VectorsRetriever(\n",
    "    retrieval_config=retrieval_cfg,\n",
    "    aws_access_key_id=config.aws_access_key,\n",
    "    aws_secret_access_key=config.aws_secret_key,\n",
    "    region=config.region,\n",
    "    variant_pipeline=variant_pipeline\n",
    ")\n",
    "\n",
    "# Steps 6-7: Sentence Expander\n",
    "expander = SentenceExpander(config)\n",
    "\n",
    "# Step 10: Context Assembler\n",
    "assembler = ContextAssembler(config)\n",
    "\n",
    "print(\"✓ All components initialized\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# QUERY\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "query = (\n",
    "    \"In the MD&A and Risk Factors sections, how did NVIDIA and Microsoft \"\n",
    "    \"discuss their AI strategy, competitive positioning, and supply chain \"\n",
    "    \"risks between 2017 and 2020?\"\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"QUERY\")\n",
    "print(\"=\"*80)\n",
    "print(query)\n",
    "print(\"\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# EXECUTE PIPELINE\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"EXECUTING RETRIEVAL PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Step 1: Entity Extraction\n",
    "print(\"→ Step 1: Entity Extraction\")\n",
    "entities = adapter.extract(query)\n",
    "print(f\"  ✓ Companies: {entities.companies.tickers}\")\n",
    "print(f\"  ✓ Years: {entities.years.years}\")\n",
    "print(f\"  ✓ Sections: {entities.sections}\\n\")\n",
    "\n",
    "# Step 2: Query Embedding\n",
    "print(\"→ Step 2: Query Embedding\")\n",
    "base_embedding = embedder.embed_query(query, entities)\n",
    "print(f\"  ✓ Generated {len(base_embedding)}-d embedding\\n\")\n",
    "\n",
    "# Step 3: Metadata Filters\n",
    "print(\"→ Step 3: Metadata Filters\")\n",
    "filtered_filters = filter_builder.build_filters(entities)\n",
    "global_filters = filter_builder.build_global_filters(entities)\n",
    "print(f\"  ✓ Filtered: {filtered_filters}\")\n",
    "print(f\"  ✓ Global: {global_filters}\\n\")\n",
    "\n",
    "# Steps 4-5: S3 Retrieval (variants generated internally)\n",
    "print(\"→ Steps 4-5: S3 Vectors Retrieval (with variants)\")\n",
    "bundle = retriever.retrieve(\n",
    "    base_embedding=base_embedding,\n",
    "    base_query=query,\n",
    "    filtered_filters=filtered_filters,\n",
    "    global_filters=global_filters\n",
    ")\n",
    "print(f\"  ✓ Retrieved: {len(bundle.union_hits)} unique hits\")\n",
    "print(f\"  ✓ Variants: {len(bundle.variant_queries)}\\n\")\n",
    "\n",
    "# Steps 6-7: Sentence Expansion\n",
    "print(\"→ Steps 6-7: Window Expansion + Deduplication\")\n",
    "unique_sentences = expander.expand_and_deduplicate(bundle.union_hits)\n",
    "print(f\"  ✓ Expanded to: {len(unique_sentences)} unique sentences\\n\")\n",
    "\n",
    "# Step 10: Context Assembly\n",
    "print(\"→ Step 10: Context Assembly\")\n",
    "context_str = assembler.assemble(unique_sentences)\n",
    "print(f\"  ✓ Assembled context ready\\n\")\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# SAVE OUTPUT\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING OUTPUT\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Create output directory\n",
    "output_dir = model_root / \"finrag_ml_tg1/rag_modules_src/test_outputs\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = output_dir / f\"assembled_context_{timestamp}.txt\"\n",
    "\n",
    "# Prepare output with metadata header\n",
    "output_content = f\"\"\"\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "FINRAG ASSEMBLED CONTEXT - RETRIEVAL PIPELINE OUTPUT\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Pipeline Execution:\n",
    "  Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "  \n",
    "Entities Extracted:\n",
    "  Companies: {', '.join(entities.companies.tickers)}\n",
    "  Years: {', '.join(map(str, entities.years.years))}\n",
    "  Sections: {', '.join(entities.sections)}\n",
    "\n",
    "Retrieval Stats:\n",
    "  S3 Hits Retrieved: {len(bundle.union_hits)}\n",
    "  Variants Generated: {len(bundle.variant_queries)}\n",
    "  Unique Sentences After Expansion: {len(unique_sentences)}\n",
    "  \n",
    "Context Stats:\n",
    "  Characters: {len(context_str):,}\n",
    "  Estimated Tokens: {len(context_str)//4:,}\n",
    "  Headers: {context_str.count('===')}\n",
    "\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "ASSEMBLED CONTEXT (Ready for LLM)\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "{context_str}\n",
    "\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "END OF CONTEXT\n",
    "═══════════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "# Save to file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(output_content)\n",
    "\n",
    "print(f\"✓ Saved assembled context to:\")\n",
    "print(f\"  {output_file}\")\n",
    "print(f\"\\nFile size: {output_file.stat().st_size:,} bytes\")\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# PREVIEW\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"CONTEXT PREVIEW (First 1000 chars)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(context_str[:1000])\n",
    "print(\"\\n[... truncated ...]\")\n",
    "print()\n",
    "\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "# SUMMARY\n",
    "# ════════════════════════════════════════════════════════════════════════════\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(f\"✓ Query processed successfully\")\n",
    "print(f\"✓ Entities: {len(entities.companies.ciks_int)} companies, {len(entities.years.years)} years\")\n",
    "print(f\"✓ Embeddings: 1 base + {len(bundle.variant_queries)} variants\")\n",
    "print(f\"✓ S3 Retrieval: {len(bundle.union_hits)} hits\")\n",
    "print(f\"✓ Expansion: {len(unique_sentences)} sentences\")\n",
    "print(f\"✓ Assembly: {len(context_str):,} chars (~{len(context_str)//4:,} tokens)\")\n",
    "print(f\"✓ Output saved: {output_file.name}\")\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"✓ SUPPLY LINE 4 COMPLETE - RAG PIPELINE WORKING END-TO-END\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa4eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f033dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
